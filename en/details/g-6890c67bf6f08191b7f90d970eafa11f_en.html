<!doctype html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>JeongmilmunhangGPT (Precision Survey Item GPT) · (자동번역) JeongmilmunhangGPT (Precision 설문 Item GPT)</title>
  <style>
    body { font-family: Arial, sans-serif; margin: 24px; line-height: 1.5; }
    .meta { color: #555; font-size: 14px; }
    h1 { margin-bottom: 6px; }
    h2 { margin-top: 22px; }
    a { text-decoration: none; }
    a:hover { text-decoration: underline; }
    .topnav { margin-bottom: 12px; }
  </style>
</head>
<body>
  <div class="topnav meta">
    <a href="../index.html">← GitHub 목록</a>
    &nbsp;|&nbsp;
    <a id="backToTistory" href="https://skcho.tistory.com/129">← 티스토리 목록</a>
  </div>

  <script>
    const p = new URLSearchParams(location.search);
    const back = p.get('back');
    if (back) document.getElementById('backToTistory').href = back;
  </script>

  <h1>JeongmilmunhangGPT (Precision Survey Item GPT) · (자동번역) JeongmilmunhangGPT (Precision 설문 Item GPT)</h1>
  <p>A survey design assistant that audits and improves questionnaire items for concept clarity, validity, wording, and response stability.</p>

  <h2>URL</h2>
  <p><a href='https://chatgpt.com/g/g-6890c67bf6f08191b7f90d970eafa11f-jeongmilmunhanggpt' target='_blank' rel='noopener noreferrer'>https://chatgpt.com/g/g-6890c67bf6f08191b7f90d970eafa11f-jeongmilmunhanggpt</a></p>

  <h2>External guides</h2>
  <p>-</p>

  <h2>Tags</h2>
  <ul><li>survey-design</li>
<li>questionnaire</li>
<li>measurement</li>
<li>validity</li>
<li>response-quality</li>
<li>web-survey</li></ul>

  <h2>Functions</h2>
  <ul><li>Derives the intended construct from each item and checks construct validity through a concept/dimension lens.</li>
<li>Detects wording risks (double-barreled items, complex clauses, double negation, ambiguous conditions) and proposes rewrites.</li>
<li>Reviews response options/scales (mutual exclusivity, exhaustiveness, neutral option, cognitive load, directional consistency) and improves them.</li>
<li>Determines when information provision is needed (jargon, policy names, missing decision criteria, time/stat claims) and designs brief neutral explanations.</li>
<li>Suggests strategies for complex items (explain-then-ask, filter-then-ask, include &#x27;don’t know&#x27;, etc.).</li>
<li>Supports survey flow/logic design (screeners, conditional follow-ups, routing based on response types).</li>
<li>Flags potentially sensitive or biased language (political bias, moral pressure, discriminatory phrasing) and offers neutral alternatives.</li>
<li>Guides end-to-end scale/index development (itemization → measurement choice → reliability/validity checks → interpretation rules).</li></ul>

  <h2>Target users</h2>
  <ul><li>Survey and research practitioners (marketing, policy, academic)</li>
<li>Scale/index developers and thesis/dissertation survey designers</li>
<li>Questionnaire reviewers (QC) and data quality owners</li></ul>

  <h2>Ideal use cases</h2>
  <ul><li>Audit and rewrite existing questionnaire items to reduce wording/interpretation risks</li>
<li>Organize items via concept–dimension mapping to remove redundancy and cover missing facets</li>
<li>Design information-provision items and decide whether to add a &#x27;don’t know&#x27; option</li>
<li>Optimize for web/mobile surveys: item length, screen splitting, and response-quality logic</li>
<li>Neutralize sensitive questions using indirect questions or scenario framing</li></ul>

  <h2>Limitations</h2>
  <ul><li>Advanced simulations (virtual respondents, reliability prediction, etc.) are not triggered unless the user explicitly requests them.</li>
<li>Statistical reliability/validity testing (e.g., Cronbach’s alpha, factor analysis) requires real data and external analysis; this GPT mainly supports process and recommendations.</li>
<li>Theory/model suggestions prioritize user-provided sources; unsupported theories are treated only as general GPT knowledge.</li>
<li>Web-survey logic/quality-control suggestions may depend on what your survey platform can implement.</li></ul>

  <h2>Example commands</h2>
  <ul><li>Classify these 12 items into constructs/dimensions, detect double-barreled or leading wording, and provide a before/after revision table.</li>
<li>Respondents may not know this topic well. Convert this into an information-provision item and recommend whether to include a &#x27;don’t know&#x27; option.</li>
<li>We’ll run this as a mobile web survey. Propose screen splitting, routing logic, and a simple attention-check plan.</li>
<li>Check for sensitive or politically biased phrasing and rewrite using indirect or scenario-based questions.</li></ul>

  <h2>Additional features</h2>
  <ul><li>Context inference module: extracts survey purpose/target/topic and proposes core research questions and priority constructs.</li>
<li>Theory-driven concept suggester: proposes candidate theories, key constructs, and alternative models.</li>
<li>Virtual-question support: criteria for when scenario-based questions are needed and a basic scenario template.</li></ul>
</body>
</html>
