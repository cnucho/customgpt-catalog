<!doctype html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Python Retrieval Assistant (PRA)</title>
  <style>
    body { font-family: Arial, sans-serif; margin: 24px; line-height: 1.5; }
    .meta { color: #555; font-size: 14px; }
    h1 { margin-bottom: 6px; }
    h2 { margin-top: 22px; }
    a { text-decoration: none; }
    a:hover { text-decoration: underline; }
    .topnav { margin-bottom: 12px; }
  </style>
</head>
<body>
  <div class="topnav meta">
    <a href="../index.html">← GitHub 목록</a>
    &nbsp;|&nbsp;
    <a id="backToTistory" href="https://skcho.tistory.com/129">← 티스토리 목록</a>
  </div>

  <script>
    // 티스토리 목록에서 넘어올 때 ?back=... 이 있으면 그쪽으로 돌아가게 함
    const p = new URLSearchParams(location.search);
    const back = p.get('back');
    if (back) document.getElementById('backToTistory').href = back;
  </script>

  <h1>Python Retrieval Assistant (PRA)</h1>
  <p>Generates robust Python scripts to retrieve specific documents, tables, datasets, and API resources with minimal friction.</p>

  <h2>URL</h2>
  <p><a href='https://chatgpt.com/g/g-69391968512c8191929a0530d6cc2799-python-retrieval-assistant-pra' target='_blank' rel='noopener noreferrer'>https://chatgpt.com/g/g-69391968512c8191929a0530d6cc2799-python-retrieval-assistant-pra</a></p>

  <h2>Tags</h2>
  <ul><li>policy</li>
<li>statistics</li>
<li>research-assistant</li></ul>

  <h2>Functions</h2>
  <ul><li>Generate Colab-ready Python scripts to download files (PDF/CSV/ZIP) from known URLs with error handling.</li>
<li>Create HTML table extraction pipelines (BeautifulSoup/pandas) and optional API retrieval methods when more stable.</li></ul>

  <h2>Target users</h2>
  <ul><li>Researchers and analysts who need reproducible data/document retrieval scripts.</li>
<li>Policy, academic, and newsroom teams collecting public datasets, reports, and tables.</li></ul>

  <h2>Ideal use cases</h2>
  <ul><li>Download a known report or dataset URL into Colab/local and save with a clean filename, logs, and retries.</li>
<li>Scrape an official webpage table into CSV (and optionally provide an API-based alternative when available).</li></ul>

  <h2>Limitations</h2>
  <ul><li>Does not perform broad exploratory research; requires a specific target resource (URL/page/API) and will not bypass authentication/paywalls.</li></ul>

  <h2>Example commands</h2>
  <ul><li>Write a Colab script to download this PDF and save it as &#x27;report_2025.pdf&#x27;: &lt;URL&gt;</li>
<li>Scrape the main statistics table from this page into UTF-8-SIG CSV with headers preserved: &lt;URL&gt;</li>
<li>This site blocks simple requests—add headers, retries, and polite rate limiting to the downloader for: &lt;URL&gt;</li>
<li>Provide two approaches to retrieve this dataset: (1) HTML scrape, (2) API if available; save outputs to ./output.csv: &lt;URL&gt;</li>
<li>Turn this multi-file ZIP download page into a script that downloads all links matching &#x27;*.zip&#x27; to ./downloads/: &lt;URL&gt;</li></ul>

  <h2>Additional features</h2>
  <ul><li>Includes step-by-step Google Colab run instructions and a download-to-local helper snippet.</li></ul>
</body>
</html>
